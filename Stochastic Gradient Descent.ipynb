{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gradient descent vs Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stochastic gradient descent (SGD or \"on-line\") typically reaches convergence much faster than batch (or \"standard\") gradient descent since it updates weight more frequently.\n",
    "\n",
    "Unlike the batch gradient descent which computes the gradient using the whole dataset, because the SGD, also known as incremental gradient descent, tries to find minimums or maximums by iteration from a single randomly picked training example, the error is typically noisier than in gradient descent.\n",
    "\n",
    "However, this can also have the advantage that stochastic gradient descent can escape shallow local minima more easily.\n",
    "\n",
    "In order to obtain accurate results with stochastic gradient descent, the data sample should be in a random order, and this is why we want to shuffle the training set for every epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given an input dataset $\\mathbf{x}$, a target $\\mathbf{y}$, hypothesis function $\\mathbf{h_{\\theta}(x)}$ and a cost function $\\mathbf{J_{\\theta}(x,y,m)}$, $\\mathbf{J_{\\theta}}$ being a function of the hypothesis function and the target and $m$ being the number of data examples,\n",
    "the optimization step in gradient descent function is as follows: $$\\theta_j := \\theta_j - \\alpha \\frac {\\partial}{\\partial \\theta_j}J_{\\theta}(x,y,m)$$\n",
    "This function is optimized until $\\mathbf{J_{\\theta}}$ is less than a tolerance value or the set number of iterations have been reached. In all cases, the optimization is performed on all examples in the data set, and that is why regular gradient descent is also known as batch gradient descent. The effect of this is an incremental movement towards the global minimum.\n",
    "With stochastic gradient descent however, the value for $m$ is set to 1, and in each iteration, for each element in the dataset the weights are optimized.\n",
    "The optimization step in stochastic gradient descent looks as follows: $$\\theta_j := \\theta_j - \\alpha \\frac {\\partial}{\\partial \\theta_j}J_{\\theta}(x_i,y_i)$$ where $i$ is the current element in the data set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "        for k in num_iterations:\n",
    "          for i in num_elements:\n",
    "            optimize weights on element i\n",
    "This allows the algorithm to move towards the optimum at the calculation of the cost related to each example instead of the cost related to all the examples if we had used regular gradient descent. We can write the SGD process as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD(f, theta0, alpha, num_iters):\n",
    "    \"\"\" \n",
    "       Arguments:\n",
    "       f -- the function to optimize, it takes a single argument\n",
    "            and yield two outputs, a cost and the gradient\n",
    "            with respect to the arguments\n",
    "       theta0 -- the initial point to start SGD from\n",
    "       num_iters -- total iterations to run SGD for       \n",
    "       Returns:\n",
    "       theta -- the parameter value after SGD finishes\n",
    "    \"\"\"\n",
    "    start_iter = 0\n",
    "    theta= theta0    \n",
    "    for iter in xrange(start_iter + 1, num_iters + 1):\n",
    "        _, grad = f(theta)\n",
    "        theta = theta - (alpha * grad) # there is NO dot product!\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__So why the name stochastic gradient descent?__\n",
    "\n",
    "The name is derived from the fact that at each optimization step, a train, target set is chosen at random and the weights are optimized accordingly. More specifically the dataset is first shuffled before running SGD to make sure that the data is randomized.\n",
    "\n",
    "__On Convergence__\n",
    "Batch GD takes a reasonably straightforward trajectory to the optimium, but in SGD, because each iteration is trying to create a better fit to the cost function, it tends to take seemingly random/ circuitous trajectory towards the optimum. Actually, it never reaches the optimum but remains in the general neighborhood of the optimum until the algorithm is stopped. SGD never converges but it ends up falling within a location close enough that the approximation of the optimum achieved using SGD can represent the global optimum\n",
    "\n",
    "sgd\n",
    "An example trajectory for SGD is shown in pink, with a corresponding trajectory for batch gradient shown in red\n",
    "__Speed of 'Convergence'__\n",
    "\n",
    "With batch GD, one optimization step is taken after evaluating the cost function over all examples of the dataset. With stochastic GD, the weights are updated for each training example, and this can lead to much faster movement towards the optimum. Usually after a few iterations or epochs over the entire dataset, the optimum will have been found\n",
    "\n",
    "__When to use SGD__\n",
    "\n",
    "If the number of training samples are large, in fact very large, then using gradient descent may take too long because in every iteration when you are updating the values of the parameters, you are running through the complete training set. On the other hand, using SGD will be faster because you use only one training sample and it starts improving itself right away from the first sample.\n",
    "SGD often converges much faster compared to GD but the error function is not as well minimized as in the case of Batch GD\n",
    "Collapse\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Their difference from Optimization point of view. Here you should use the following terms: epoch, total amount of iterations, batch size, minibatch\n",
    "In Gradient Descent or Batch Gradient Descent, we use the whole training data per epoch whereas, in Stochastic Gradient Descent, we use only single training example per epoch and Mini-batch Gradient Descent lies in between of these two extremes, in which we can use a mini-batch(small portion) of training data per epoch, thumb rule for selecting the size of mini-batch is in power of 2 like 32, 64, 128 etc.\n",
    "\n",
    "__Gradient Descent__\n",
    "This is an iterative optimization algorithm for finding the minimum of a function. The algorithm takes steps proportional to the negative gradient of the function at the current point. \n",
    "\n",
    "$$\\theta := \\theta - \\alpha\\frac{\\partial }{\\partial \\theta_j}J(\\theta) $$\n",
    "\n",
    "\n",
    "Here,\n",
    "$\\theta_j$ corresponds to the parameter, $\\alpha$ is the learning rate that is the step size multiplied by the derivative of the function by which to move on the loss function curve toward the minima.\n",
    "\n",
    "In deep learning neural networks are trained by defining a loss function and optimizing the parameters of the network to obtain the minimum of the function. The optimization is done using the gradient descent algorithm which operates in these two steps:\n",
    "\n",
    "Compute the slope (gradient) that is first order derivative of the function at the current point.\n",
    "Move in the opposite direction of the slope increase from the current point by the computed amount.\n",
    "Stochastic Gradient Descent\n",
    "In this method one training sample (example) is passed through the neural network at a time and the parameters (weights) of each layer are updated with the computed gradient. So, at a time a single training sample is passed through the network and its corresponding loss is computed. The parameters of all the layers of the network are updated after every training sample. For example, if the training set contains 100 samples then the parameters are updated 100 times that is one time after every individual example is passed through the network. Following is the gradient descent equation and for stochastic gradient descent it is iterated over ’n’ times for ’n’ training samples in the training set.\n",
    "\n",
    "__Advantages of Stochastic Gradient Descent__\n",
    "\n",
    "It is easier to fit into memory due to a single training sample being processed by the network\n",
    "It is computationally fast as only one sample is processed at a time\n",
    "For larger datasets it can converge faster as it causes updates to the parameters more frequently\n",
    "Due to frequent updates the steps taken towards the minima of the loss function have oscillations which can help getting out of local minimums of the loss function (in case the computed position turns out to be the local minimum)\n",
    "\n",
    "__Disadvantages of Stochastic Gradient Descent__\n",
    "\n",
    "Due to frequent updates the steps taken towards the minima are very noisy. This can often lead the gradient descent into other directions.\n",
    "Also, due to noisy steps it may take longer to achieve convergence to the minima of the loss function\n",
    "Frequent updates are computationally expensive due to using all resources for processing one training sample at a time\n",
    "It loses the advantage of vectorized operations as it deals with only a single example at a time\n",
    "Batch Gradient Descent\n",
    "The concept of carrying out gradient descent is the same as stochastic gradient descent. The difference is that instead of updating the parameters of the network after computing the loss of every training sample in the training set, the parameters are updated once that is after all the training examples have been passed through the network. For example, if the training dataset contains 100 training examples then the parameters of the neural network are updated once. The equation in Figure2 is iterated over only once.\n",
    "\n",
    "__Advantages of Batch Gradient Descent__\n",
    "Less oscillations and noisy steps taken towards the global minima of the loss function due to updating the parameters by computing the average of all the training samples rather than the value of a single sample\n",
    "\n",
    "It can benefit from the vectorization which increases the speed of processing all training samples together\n",
    "It produces a more stable gradient descent convergence and stable error gradient than stochastic gradient descent\n",
    "It is computationally efficient as all computer resources are not being used to process a single sample rather are being used for all training samples\n",
    "__Disadvantages of Batch Gradient Descent__\n",
    "\n",
    "Sometimes a stable error gradient can lead to a local minima and unlike stochastic gradient descent no noisy steps are there to help get out of the local minima\n",
    "The entire training set can be too large to process in the memory due to which additional memory might be needed\n",
    "Depending on computer resources it can take too long for processing all the training samples as a batch\n",
    "\n",
    "__Mini Batch Gradient Descent Batch : A Compromise__\n",
    "This is a mixture of both stochastic and batch gradient descent. The training set is divided into multiple groups called batches. Each batch has a number of training samples in it. At a time a single batch is passed through the network which computes the loss of every sample in the batch and uses their average to update the parameters of the neural network. For example, say the training set has 100 training examples which is divided into 5 batches with each batch containing 20 training examples. This means that the equation in figure2 will be iterated over 5 times (number of batches).\n",
    "This ensures the following advantages of both stochastic and batch gradient descent are used due to which Mini Batch Gradient Descent is most commonly used in practice.\n",
    "\n",
    "Easily fits in the memory\n",
    "It is computationally efficient\n",
    "Benefit from vectorization\n",
    "If stuck in local minimums, some noisy steps can lead the way out of them\n",
    "Average of the training samples produces stable error gradients and convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
